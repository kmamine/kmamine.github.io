---
layout: page
title: Research
subtitle: Exploring the frontiers of computer vision and visual attention
permalink: /research/
---

<div class="container">

<h2>About My Research</h2>

<p>
    My research focuses on understanding and modeling human visual attention mechanisms, 
    particularly in the context of computer vision and deep learning. I work on developing 
    AI systems that can predict where humans look in images and videos, which has applications 
    in areas ranging from cultural heritage preservation to medical imaging.
</p>

<h2>Current Focus Areas</h2>

<h3>Visual Saliency Prediction</h3>
<p>
    I develop deep learning models that predict where humans are likely to look when viewing 
    an image. This involves understanding both bottom-up visual features (contrast, color, 
    motion) and top-down factors (task, context, semantic content). Key contributions include:
</p>
<ul>
    <li>SATSal: A multi-level self-attention architecture for visual saliency prediction</li>
    <li>Salypath: Deep-based architecture for visual attention prediction</li>
    <li>SalyPath360: Saliency and scanpath prediction for 360° images</li>
</ul>

<h3>Scanpath Prediction</h3>
<p>
    Beyond predicting where people look, I work on modeling the sequential nature of eye 
    movements. This involves predicting not just saliency maps, but the actual sequence 
    of fixations (scanpaths) that a viewer would make.
</p>
<ul>
    <li>Self-supervised scanpath prediction frameworks</li>
    <li>Domain adaptive solutions for painting images</li>
    <li>Simple and efficient deep scanpath prediction</li>
</ul>

<h3>Medical Imaging</h3>
<p>
    Applying computer vision techniques to medical image analysis, with a focus on 
    automating diagnosis and quality assessment tasks.
</p>
<ul>
    <li>Knee osteoarthritis severity assessment using Swin Transformer</li>
    <li>Deep-based quality assessment of medical images through domain adaptation</li>
    <li>Graph-based morphology-aware classification approaches</li>
</ul>

<h3>LLM Research</h3>
<p>
    More recently, I've been exploring large language models, particularly focusing on 
    understanding and mitigating hallucinations in LLM outputs.
</p>
<ul>
    <li>Insights into classifying and mitigating LLMs' hallucinations</li>
</ul>

<h2>Collaborations</h2>

<p>
    I collaborate with researchers from multiple institutions:
</p>
<ul>
    <li><strong>PRISME Laboratory</strong> - University of Orleans, France</li>
    <li><strong>L2TI</strong> - Institut Galilée, University Sorbonne Paris Nord</li>
    <li><strong>IULM University</strong> - Milan, Italy</li>
    <li><strong>CNR ISASI</strong> - Institute of Applied Sciences & Intelligent Systems</li>
    <li><strong>Northwestern University</strong> - Feinberg School of Medicine</li>
</ul>

<h2>Research Impact</h2>

<div class="hero-stats" style="justify-content: flex-start; margin-top: 1rem;">
    <div class="stat-item">
        <span class="stat-number">160+</span>
        <span class="stat-label">Citations</span>
    </div>
    <div class="stat-item">
        <span class="stat-number">8</span>
        <span class="stat-label">H-Index</span>
    </div>
    <div class="stat-item">
        <span class="stat-number">5</span>
        <span class="stat-label">i10-Index</span>
    </div>
</div>

</div>
